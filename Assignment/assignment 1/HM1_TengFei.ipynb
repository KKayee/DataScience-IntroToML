{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz, plot_tree\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from IPython.display import Image  \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pydotplus\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 1: Remove the rows with missing labels (’label’) and rows with more than 7 missing features. Report the remaining number of rows. (2 mark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>id</th>\n",
       "      <th>fea_1</th>\n",
       "      <th>fea_2</th>\n",
       "      <th>fea_3</th>\n",
       "      <th>fea_4</th>\n",
       "      <th>fea_5</th>\n",
       "      <th>fea_6</th>\n",
       "      <th>fea_7</th>\n",
       "      <th>fea_8</th>\n",
       "      <th>fea_9</th>\n",
       "      <th>fea_10</th>\n",
       "      <th>fea_11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>59004779</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1277.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>113000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>341759.0</td>\n",
       "      <td>207.173840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>58990862</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1298.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>72001.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>58995168</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1335.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>151000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>60084.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>54987320</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>59000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>450081.0</td>\n",
       "      <td>197.403141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>59005995</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1217.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>56000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>60091.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label        id  fea_1   fea_2  fea_3     fea_4  fea_5  fea_6  fea_7  \\\n",
       "0    0.0  59004779    4.0  1277.0    1.0  113000.0    2.0    8.0   -1.0   \n",
       "1    0.0  58990862    7.0  1298.0    1.0  110000.0    2.0   11.0   -1.0   \n",
       "2    1.0  58995168    7.0  1335.5    1.0  151000.0    2.0   11.0    5.0   \n",
       "3    0.0  54987320    7.0     NaN    2.0   59000.0    2.0   11.0    5.0   \n",
       "4    0.0  59005995    6.0  1217.0    3.0   56000.0    2.0    6.0   -1.0   \n",
       "\n",
       "   fea_8  fea_9    fea_10      fea_11  \n",
       "0  100.0    3.0  341759.0  207.173840  \n",
       "1  101.0    5.0   72001.0         NaN  \n",
       "2  110.0    3.0   60084.0         NaN  \n",
       "3  108.0    4.0  450081.0  197.403141  \n",
       "4  100.0    3.0   60091.0         NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "dat = pd.read_csv('data/customer_data.csv')\n",
    "dat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Rows: 1124\n",
      "after remove NA-label row: 1110\n",
      "after drop more than 7 feature: 1095\n"
     ]
    }
   ],
   "source": [
    "print('Original Rows: %s' % len(dat))\n",
    "\n",
    "dat_remove_label = dat.dropna(subset=['label'])\n",
    "print('after remove NA-label row: %s' % len(dat_remove_label))\n",
    "\n",
    "dat_remove_7_missing = dat_remove_label.iloc[:, 2:] # drop `label` because it's not a feature\n",
    "dat_remove_7_missing = dat_remove_7_missing.dropna(thresh=8)\n",
    "print('after drop more than 7 feature: %s' % len(dat_remove_7_missing))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 2: Remove features with > 50% of missing values. For other features with missing values fill them with the mean of the corresponding features. Report the removed features (if any) and standard deviation of features with missing values after filling. (2 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original columns: 11\n",
      "after remove feature has 50pct  NA: 10\n",
      "removed feature is fea_11\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "fea_1          1.378574\n",
       "fea_2         48.151339\n",
       "fea_3          0.876765\n",
       "fea_4      89256.523379\n",
       "fea_5          0.260353\n",
       "fea_6          2.676198\n",
       "fea_7          2.970648\n",
       "fea_8         11.977444\n",
       "fea_9          0.857937\n",
       "fea_10    152455.809399\n",
       "dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('original columns: %s' % len(dat_remove_7_missing.columns))\n",
    "\n",
    "dat_remove_50pct = dat_remove_7_missing.dropna(thresh=0.5 * len(dat_remove_7_missing), axis='columns')\n",
    "dat_fill_mean = dat_remove_50pct.fillna(dat_remove_50pct.mean())\n",
    "print('after remove feature has 50pct  NA: %s' % len(dat_remove_50pct.columns))\n",
    "\n",
    "for feature in dat_remove_7_missing.columns:\n",
    "    if feature not in dat_fill_mean.columns:\n",
    "        print('removed feature is %s' % feature)\n",
    "\n",
    "dat_fill_mean.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 3: Train Decision Tree model on train data for criterions = {’gini’, ’entropy’} and report the accuracies on the validation data. Select the best criterion and report the accuracy on the test data. (1 mark)\n",
    "\n",
    "Question 4: Use the criterion selected above to train Decision Tree model on train data for min samples split={2,5,10,20} and report the accuracies on the validation data. Select the best parameter and report the accuracy on the test data. (2 marks)\n",
    "\n",
    "Question 5: Use the parameters selected above (Q4 and Q5) to train Decision Tree model using the first 50, 100, 200, 400, 600 and 704 samples from train data. Keep the validation set unchanged during this analysis. Report and plot the accuracies on the validation data. (2 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fea_1</th>\n",
       "      <th>fea_2</th>\n",
       "      <th>fea_3</th>\n",
       "      <th>fea_4</th>\n",
       "      <th>fea_5</th>\n",
       "      <th>fea_6</th>\n",
       "      <th>fea_7</th>\n",
       "      <th>fea_8</th>\n",
       "      <th>fea_9</th>\n",
       "      <th>fea_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>946</th>\n",
       "      <td>7.0</td>\n",
       "      <td>1275.500000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>136000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>151304.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>7.0</td>\n",
       "      <td>1304.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>63000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>60095.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>7.0</td>\n",
       "      <td>1296.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>76000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>72001.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1250.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>78000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>350092.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>7.0</td>\n",
       "      <td>1257.500000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>95000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>450015.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1230.500000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>61000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>60020.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>936</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1305.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>128000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>60042.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>7.0</td>\n",
       "      <td>1284.180818</td>\n",
       "      <td>2.0</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>151304.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1191.500000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>61000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>72001.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1350.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>237000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>60085.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>704 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     fea_1        fea_2  fea_3     fea_4  fea_5  fea_6  fea_7  fea_8  fea_9  \\\n",
       "946    7.0  1275.500000    3.0  136000.0    2.0   11.0    5.0  113.0    4.0   \n",
       "392    7.0  1304.000000    3.0   63000.0    2.0   11.0    5.0  110.0    4.0   \n",
       "510    7.0  1296.500000    1.0   76000.0    2.0   11.0   10.0  113.0    4.0   \n",
       "875    5.0  1250.000000    3.0   78000.0    2.0   15.0    5.0   82.0    5.0   \n",
       "420    7.0  1257.500000    3.0   95000.0    1.0   11.0    4.0  111.0    4.0   \n",
       "..     ...          ...    ...       ...    ...    ...    ...    ...    ...   \n",
       "567    5.0  1230.500000    3.0   61000.0    2.0   15.0    5.0  109.0    4.0   \n",
       "936    4.0  1305.500000    1.0  128000.0    2.0    8.0    3.0   96.0    3.0   \n",
       "534    7.0  1284.180818    2.0   70000.0    2.0   11.0    9.0  110.0    4.0   \n",
       "734    5.0  1191.500000    3.0   61000.0    2.0   15.0   -1.0  111.0    4.0   \n",
       "52     5.0  1350.500000    1.0  237000.0    2.0   15.0    8.0   86.0    3.0   \n",
       "\n",
       "       fea_10  \n",
       "946  151304.0  \n",
       "392   60095.0  \n",
       "510   72001.0  \n",
       "875  350092.0  \n",
       "420  450015.0  \n",
       "..        ...  \n",
       "567   60020.0  \n",
       "936   60042.0  \n",
       "534  151304.0  \n",
       "734   72001.0  \n",
       "52    60085.0  \n",
       "\n",
       "[704 rows x 10 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_feature = pd.read_csv('data/customer_data_train.csv').iloc[:, 1:]\n",
    "train_feature = pd.read_csv('data/customer_data_train.csv', index_col=0)\n",
    "train_label = pd.read_csv('data/customer_data_train_labels.csv', index_col=0)\n",
    "\n",
    "test_feature = pd.read_csv('data/customer_data_test.csv', index_col=0)\n",
    "test_label = pd.read_csv('data/customer_data_test_labels.csv', index_col=0)\n",
    "\n",
    "train_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(clf, feature_names, label_names):\n",
    "\n",
    "    plt.figure(figsize=(60, 30))\n",
    "\n",
    "    return plot_tree(clf, feature_names=feature_names, class_names=label_names, filled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "criterions gini, min_split 2, samples_cut 50\n",
      "accuracy = 0.6606334841628959\n",
      "criterions gini, min_split 2, samples_cut 100\n",
      "accuracy = 0.7149321266968326\n",
      "criterions gini, min_split 2, samples_cut 200\n",
      "accuracy = 0.6923076923076923\n",
      "criterions gini, min_split 2, samples_cut 400\n",
      "accuracy = 0.6606334841628959\n",
      "criterions gini, min_split 2, samples_cut 600\n",
      "accuracy = 0.669683257918552\n",
      "criterions gini, min_split 2, samples_cut 704\n",
      "accuracy = 0.7013574660633484\n",
      "criterions gini, min_split 5, samples_cut 50\n",
      "accuracy = 0.6515837104072398\n",
      "criterions gini, min_split 5, samples_cut 100\n",
      "accuracy = 0.7330316742081447\n",
      "criterions gini, min_split 5, samples_cut 200\n",
      "accuracy = 0.7013574660633484\n",
      "criterions gini, min_split 5, samples_cut 400\n",
      "accuracy = 0.6877828054298643\n",
      "criterions gini, min_split 5, samples_cut 600\n",
      "accuracy = 0.6832579185520362\n",
      "criterions gini, min_split 5, samples_cut 704\n",
      "accuracy = 0.6742081447963801\n",
      "criterions gini, min_split 10, samples_cut 50\n",
      "accuracy = 0.751131221719457\n",
      "criterions gini, min_split 10, samples_cut 100\n",
      "accuracy = 0.7104072398190046\n",
      "criterions gini, min_split 10, samples_cut 200\n",
      "accuracy = 0.6742081447963801\n",
      "criterions gini, min_split 10, samples_cut 400\n",
      "accuracy = 0.7104072398190046\n",
      "criterions gini, min_split 10, samples_cut 600\n",
      "accuracy = 0.7013574660633484\n",
      "criterions gini, min_split 10, samples_cut 704\n",
      "accuracy = 0.7058823529411765\n",
      "criterions gini, min_split 20, samples_cut 50\n",
      "accuracy = 0.7873303167420814\n",
      "criterions gini, min_split 20, samples_cut 100\n",
      "accuracy = 0.7375565610859729\n",
      "criterions gini, min_split 20, samples_cut 200\n",
      "accuracy = 0.7149321266968326\n",
      "criterions gini, min_split 20, samples_cut 400\n",
      "accuracy = 0.7285067873303167\n",
      "criterions gini, min_split 20, samples_cut 600\n",
      "accuracy = 0.7420814479638009\n",
      "criterions gini, min_split 20, samples_cut 704\n",
      "accuracy = 0.746606334841629\n",
      "criterions entropy, min_split 2, samples_cut 50\n",
      "accuracy = 0.6425339366515838\n",
      "criterions entropy, min_split 2, samples_cut 100\n",
      "accuracy = 0.7013574660633484\n",
      "criterions entropy, min_split 2, samples_cut 200\n",
      "accuracy = 0.6968325791855203\n",
      "criterions entropy, min_split 2, samples_cut 400\n",
      "accuracy = 0.6470588235294118\n",
      "criterions entropy, min_split 2, samples_cut 600\n",
      "accuracy = 0.669683257918552\n",
      "criterions entropy, min_split 2, samples_cut 704\n",
      "accuracy = 0.7194570135746606\n",
      "criterions entropy, min_split 5, samples_cut 50\n",
      "accuracy = 0.669683257918552\n",
      "criterions entropy, min_split 5, samples_cut 100\n",
      "accuracy = 0.7104072398190046\n",
      "criterions entropy, min_split 5, samples_cut 200\n",
      "accuracy = 0.6923076923076923\n",
      "criterions entropy, min_split 5, samples_cut 400\n",
      "accuracy = 0.6425339366515838\n",
      "criterions entropy, min_split 5, samples_cut 600\n",
      "accuracy = 0.6742081447963801\n",
      "criterions entropy, min_split 5, samples_cut 704\n",
      "accuracy = 0.7058823529411765\n",
      "criterions entropy, min_split 10, samples_cut 50\n",
      "accuracy = 0.6063348416289592\n",
      "criterions entropy, min_split 10, samples_cut 100\n",
      "accuracy = 0.6968325791855203\n",
      "criterions entropy, min_split 10, samples_cut 200\n",
      "accuracy = 0.669683257918552\n",
      "criterions entropy, min_split 10, samples_cut 400\n",
      "accuracy = 0.6832579185520362\n",
      "criterions entropy, min_split 10, samples_cut 600\n",
      "accuracy = 0.6923076923076923\n",
      "criterions entropy, min_split 10, samples_cut 704\n",
      "accuracy = 0.7194570135746606\n",
      "criterions entropy, min_split 20, samples_cut 50\n",
      "accuracy = 0.6787330316742082\n",
      "criterions entropy, min_split 20, samples_cut 100\n",
      "accuracy = 0.7285067873303167\n",
      "criterions entropy, min_split 20, samples_cut 200\n",
      "accuracy = 0.6877828054298643\n",
      "criterions entropy, min_split 20, samples_cut 400\n",
      "accuracy = 0.7013574660633484\n",
      "criterions entropy, min_split 20, samples_cut 600\n",
      "accuracy = 0.7239819004524887\n",
      "criterions entropy, min_split 20, samples_cut 704\n",
      "accuracy = 0.7330316742081447\n"
     ]
    }
   ],
   "source": [
    "criterions = ['gini', 'entropy']\n",
    "min_split = [2, 5, 10, 20]\n",
    "samples_cut = [50, 100, 200, 400, 600, 704]\n",
    "\n",
    "for cri in criterions:\n",
    "    for minsplit in min_split:\n",
    "        for cut in samples_cut:\n",
    "\n",
    "            clf = DecisionTreeClassifier(criterion=cri, min_samples_split=minsplit, random_state=34)\n",
    "            clf.fit(train_feature[:cut], train_label[:cut])\n",
    "            predictions = clf.predict(test_feature)\n",
    "\n",
    "            print('criterions %(cri)s, min_split %(minsplit)s, samples_cut %(cut)s' % {'cri': cri, 'minsplit': minsplit, 'cut': cut})\n",
    "            print('accuracy = %s' % str(accuracy_score(test_label, predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 6: Use the test data to compute the confusion matrix for the predictions of your model. Report the confusion matrix. (1 mark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nearest Neighbor\n",
    "Normalize Data: Normalize features such that for each feature the mean is 0 and the standard deviation is 1 in the train+validation data. Use the normalizing factors calculated on train+validation data to modify the values in train, validation and test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 7: Train k-nn model on train + validation data and report accuracy on test data. Use Euclidean distance and k=3. (1 mark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 8: Train the model on train data for distance metrics defined by l1,linf, l2. Report the accuracies on the validation data. Select the best metric and report the accuracy on the test data for the selected metric. Use k=3. (1 mark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 9: Train the k-nn model on train data for k=1,3,5,7,9. Report and plot the accuracies on the validation data. Select the best ’k’ value and report the accuracy on the test data for the selected ’k’. Use Chebyshev distance. (2 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 10: Instead of using full train data, train the model using the first 50, 100, 200, 400, 600 and 704 data samples from train data. Keep the validation set unchanged during this analysis. Report and plot the accuracies on the validation data. Use Chebyshev distance and k=3. Note: Don’t shuffle the data and use only the ’first n samples’, otherwise your answers may differ. (2 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 11: Train a k-nn model with k=3 and k=7 with the Chebyshev distance on the train and validation data combined. Plot the ROC curve for the prediction you get on the test data for both models. Also report the accuracy, precision, recall and F-1 score.\n",
    "Please comment on the evaluation results and the ROC curve, which model is better?(4 points)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
